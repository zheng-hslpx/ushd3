#### 1. improved_config.json
配置文件，存储环境、模型和训练参数，结构清晰便于调参
```json
{
  "env_paras": {  // 环境参数
    "num_usvs": 5,  // USV数量
    "num_tasks": 24,  // 任务数量
    "map_size": [120, 120],  // 地图尺寸
    "battery_capacity": 220.0,  // 电池容量
    "usv_speed": 5.0,  // USV速度
    "charge_time": 30.0,  // 充电时间
    "device": "cuda:0",  // 计算设备
    "min_task_time_visual": 5.0,  // 可视化时短任务判断阈值
    "reward_config": {  // 奖励函数参数
      "use_potential_based_reward": false,  // 是否使用基于势能的奖励
      "makespan_normalization": 200.0,  // makespan（最大完成时间）归一化系数
      "_comment": "基于第12次成功配置的极保守调整",
      "w_makespan_improvement": 1.2,  // makespan改进权重
      "w_makespan_penalty": 0.6,  // makespan惩罚权重
      "w_progress": 2.3,  // 任务进度权重
      "w_efficiency": 0.5,  // 效率权重
      "w_step_efficiency": 0.3,  // 步骤效率权重
      "w_balance": 0.2,  // 负载平衡权重
      "w_final_balance": 3.0,  // 最终平衡权重
      "w_variance": 0.18,  // 方差惩罚权重
      "w_distance": 0.4,  // 距离惩罚权重
      "w_timing": 0.8,  // 时间惩罚权重
      "baseline_reward": 51,  // 基准奖励
      "coverage_bonus": 3.0,  // 覆盖度奖励
      "empty_usv_terminal_penalty": 25.0  // 闲置USV的终端惩罚
    },
    "dynamic_masking_config": {  // 动态掩码配置（限制无效动作）
      "enabled": true,  // 是否启用
      "max_load_ratio": 1.4  // 最大负载比率
    }
  },
  
  "model_paras": {  // 模型参数
    "embedding_dim": 64,  // 嵌入维度
    "num_heads": 1,  // 注意力头数（通用）
    "num_attention_heads": 4,  // 图注意力头数
    "num_hgnn_layers": 3,  // HGNN层数
    "eta_neighbors": 3,  // 邻居选择数量
    "mlp_hidden_dim": 128,  // MLP隐藏层维度
    "n_hidden_actor": 3,  // Actor网络隐藏层数
    "n_hidden_critic": 5,  // Critic网络隐藏层数
    "n_latent_actor": 128,  // Actor潜在维度
    "n_latent_critic": 256,  // Critic潜在维度
    "dropout": 0.15,  // Dropout比率
    "device": "cuda:0",  // 模型设备
    "use_batch_norm": true,  // 是否使用批归一化
    "graph_pool": "mean",  // 图池化方式
    "residual_blocks": 2,  // 残差块数量
    "_exploration_comment": "=== 探索机制核心参数 ===",
    "initial_epsilon": 0.3,  // 初始探索率
    "min_epsilon": 0.05,  // 最小探索率
    "epsilon_decay": 0.995,  // 探索率衰减系数
    "exploration_steps": 1000,  // 探索步数
    "adaptive_epsilon": true  // 是否自适应探索率
  },
  
  "train_paras": {  // 训练参数
    "_comment": "增强训练稳定性 + 探索机制参数",
    "lr": 0.0002,  // 学习率
    "betas": [0.9, 0.999],  // Adam优化器beta参数
    "gamma": 0.99,  // 折扣因子
    "gae_lambda": 0.95,  // GAE系数
    "K_epochs": 4,  // PPO更新轮数
    "eps_clip": 0.15,  // PPO剪辑参数
    "A_coeff": 1.0,  // Actor损失系数
    "vf_coeff": 0.4,  // Critic损失系数
    "entropy_coeff": 0.015,  // 熵奖励系数（鼓励探索）
    "max_grad_norm": 0.5,  // 梯度裁剪阈值
    "warmup_steps": 120,  // 预热步数
    "lr_decay_patience": 60,  // 学习率衰减耐心值
    "min_lr": 5e-07,  // 最小学习率
    "early_stop_patience": 200,  // 早停耐心值
    "max_episodes": 1000,  // 最大训练回合数
    "minibatch_size": 64,  // 小批量大小
    "save_frequency": 80,  // 模型保存频率
    "eval_frequency": 25,  // 评估频率
    "_exploration_schedule_comment": "=== 探索机制训练调度参数 ===",
    "epsilon_update_frequency": 10,  // 探索率更新频率
    "exploration_performance_threshold": -50,  // 探索性能阈值
    "adaptive_exploration": true,  // 是否自适应探索
    "exploration_boost_episodes": 100,  // 探索增强回合数
    "_debug_comment": "=== 调试和可视化参数 ===",
    "debug_mode": false,  // 调试模式
    "plot_metrics_every": 50,  // 指标绘图频率
    "report_root": "results/reports",  // 报告根目录
    "report_episodes": 50,  // 报告回合数
    "viz": true,  // 是否可视化
    "viz_name": "USV_EXPLORATION_V21",  // 可视化环境名称
    "save_root": "results/saved_models_2",  // 模型保存根目录
    "save_only_last": false,  // 是否只保存最后模型
    "run_name": "Exploration_Enhanced_v21"  // 运行名称
  }
}
```


#### 2. data_generator.py
生成USV和任务的初始数据实例，用于环境初始化
```python
import json
import numpy as np
from typing import List, Tuple, Dict
from .usv_env import USVState, TaskState  # 导入状态类

class USVTaskDataGenerator:
    def __init__(self, config: Dict):
        # 从配置初始化参数
        self.num_usvs = int(config['num_usvs'])  # USV数量
        self.num_tasks = int(config['num_tasks'])  # 任务数量
        self.map_size = config['map_size']  # 地图尺寸
        self.battery_capacity = float(config['battery_capacity'])  # 电池容量
        # 允许从配置覆盖最小/最大处理时间
        self.min_processing_time = float(config.get('min_processing_time', 8.0))  # 最小执行时间
        self.max_processing_time = float(config.get('max_processing_time', 30.0))  # 最大执行时间
        self.task_distribution = config.get('task_distribution', 'uniform')  # 任务分布类型

    def generate_instance(self, seed: int = None) -> Tuple[List[USVState], List[TaskState]]:
        # 生成USV和任务实例
        if seed is not None:
            np.random.seed(seed)  # 设置随机种子，保证可复现
        # 初始化USV状态：位置(0,0)、满电、空闲
        usvs = [USVState(id=i, position=np.array([0.0, 0.0], dtype=np.float32),
                         battery=self.battery_capacity, status='idle')
                for i in range(self.num_usvs)]

        # 随机生成任务位置（均匀分布在地图内）
        positions = np.random.uniform([0,0], self.map_size, size=(self.num_tasks, 2)).astype(np.float32)
        tasks = []
        for i in range(self.num_tasks):
            # 随机生成基础处理时间
            base = float(np.random.uniform(self.min_processing_time, self.max_processing_time))
            # 模糊三角取值（增加任务时间的不确定性）
            fuzzy = (max(self.min_processing_time*0.8, 0.8*base),  # 最小值
                     max(self.min_processing_time, base),  # 最可能值
                     max(self.min_processing_time*1.2, 1.2*base))  # 最大值
            # 计算期望处理时间（加权平均）
            expected = max(self.min_processing_time, (fuzzy[0] + 2*fuzzy[1] + fuzzy[2]) / 4.0)
            # 创建任务状态实例
            tasks.append(TaskState(id=i, position=positions[i],
                                   processing_time=expected, fuzzy_time=fuzzy, status='unscheduled'))
        return usvs, tasks  # 返回USV和任务列表

    def save_instance(self, usvs: List[USVState], tasks: List[TaskState], filename: str):
        # 保存生成的实例到JSON文件
        data = {
            'num_usvs': len(usvs),
            'num_tasks': len(tasks),
            # 存储USV信息：ID、位置、电池
            'usvs': [{'id': u.id, 'position': u.position.tolist(), 'battery': u.battery} for u in usvs],
            # 存储任务信息：ID、位置、模糊时间、处理时间
            'tasks': [{'id': t.id, 'position': t.position.tolist(),
                       'fuzzy_time': t.fuzzy_time, 'processing_time': t.processing_time} for t in tasks]
        }
        with open(filename, 'w') as f:
            json.dump(data, f, indent=2)  # 写入文件
```


#### 3. hgnn_model.py
实现基于图神经网络的特征提取模型，包含位置编码、多头图注意力等核心组件
```python
from typing import Tuple
import torch
import torch.nn as nn
import torch.nn.functional as F
import math

class PositionalEncoding(nn.Module):
    """新增：位置编码增强空间特征"""
    def __init__(self, d_model: int, max_len: int = 200):
        super().__init__()
        # 初始化位置编码矩阵（max_len x d_model）
        pe = torch.zeros(max_len, d_model)
        # 位置索引（0到max_len-1）
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        # 计算衰减项（遵循Transformer位置编码公式）
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        # 偶数维度用正弦编码
        pe[:, 0::2] = torch.sin(position * div_term)
        # 奇数维度用余弦编码
        pe[:, 1::2] = torch.cos(position * div_term)
        # 注册为非参数缓冲区（不参与训练但会被保存）
        self.register_buffer('pe', pe)

    def forward(self, x, positions):
        # positions: [B, N, 2] - 归一化的x,y坐标
        B, N, _ = positions.shape
        # 将归一化坐标映射到索引（0-199）
        pos_indices = (positions * 100).long().clamp(0, 199)  # 简单的位置索引映射
        # 组合x和y方向的位置编码
        pos_enc = self.pe[pos_indices[:,:,0]] + self.pe[pos_indices[:,:,1]]
        # 确保维度匹配（防止位置编码维度超过输入特征维度）
        return x + pos_enc[:, :, :x.size(-1)]

class MultiHeadGraphAttention(nn.Module):
    """核心改进：多头图注意力机制"""
    def __init__(self, input_dim: int, output_dim: int, num_heads: int = 4, dropout: float = 0.1):
        super().__init__()
        # 确保输出维度可被头数整除
        assert output_dim % num_heads == 0
        self.num_heads = num_heads  # 注意力头数
        self.head_dim = output_dim // num_heads  # 每个头的维度
        self.scale = math.sqrt(self.head_dim)  # 缩放因子（防止梯度消失）
        
        # 定义Q、K、V的线性变换层
        self.W_Q = nn.Linear(input_dim, output_dim, bias=False)
        self.W_K = nn.Linear(input_dim, output_dim, bias=False) 
        self.W_V = nn.Linear(input_dim, output_dim, bias=False)
        # 输出线性变换
        self.W_O = nn.Linear(output_dim, output_dim)
        
        self.dropout = nn.Dropout(dropout)  # Dropout层
        self.layer_norm = nn.LayerNorm(output_dim)  # 层归一化
        
        # 残差连接的投影（当输入输出维度不同时）
        self.residual_proj = nn.Linear(input_dim, output_dim) if input_dim != output_dim else nn.Identity()
        
        self._init_weights()  # 初始化权重
    
    def _init_weights(self):
        # 初始化线性层权重（Xavier均匀初始化）
        for module in [self.W_Q, self.W_K, self.W_V, self.W_O]:
            nn.init.xavier_uniform_(module.weight, gain=1/math.sqrt(2))
    
    def forward(self, query, key, value, mask=None):
        B, N, _ = query.shape  # B:批次大小, N:query节点数
        M = key.shape[1]  # M:key/value节点数
        
        # 多头变换：[B, N, output_dim] -> [B, num_heads, N, head_dim]
        Q = self.W_Q(query).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)
        K = self.W_K(key).view(B, M, self.num_heads, self.head_dim).transpose(1, 2)
        V = self.W_V(value).view(B, M, self.num_heads, self.head_dim).transpose(1, 2)
        
        # 注意力计算：Q*K^T / sqrt(head_dim)
        attn = torch.matmul(Q, K.transpose(-2, -1)) / self.scale
        
        # 应用掩码（忽略无效节点）
        if mask is not None:
            mask = mask.unsqueeze(1).expand(-1, self.num_heads, -1, -1)  # 扩展到多头
            attn = attn.masked_fill(mask == 0, float('-inf'))  # 掩码位置设为负无穷
        
        # 计算注意力权重（softmax）
        attn = F.softmax(attn, dim=-1)
        attn = self.dropout(attn)  # 应用dropout
        
        # 注意力加权求和（与V相乘）
        out = torch.matmul(attn, V)
        # 重塑回[B, N, output_dim]
        out = out.transpose(1, 2).contiguous().view(B, N, -1)
        out = self.W_O(out)  # 输出线性变换
        
        # 残差连接和层归一化
        residual = self.residual_proj(query)
        return self.layer_norm(out + residual)

class EnhancedUSVNodeEmbedding(nn.Module):
    """增强版USV节点嵌入"""
    def __init__(self, usv_dim: int, task_dim: int, edge_dim: int, embedding_dim: int, 
                 num_heads: int = 4, dropout: float = 0.1):
        super().__init__()
        self.dtype = torch.float32  # 数据类型
        
        # 核心修复：多头注意力在embedding_dim上操作
        self.usv_self_attn = MultiHeadGraphAttention(embedding_dim, embedding_dim, num_heads, dropout)  # USV自注意力
        self.usv_task_attn = MultiHeadGraphAttention(embedding_dim, embedding_dim, num_heads, dropout)  # USV-任务交叉注意力
        
        # 特征投影层（将原始特征映射到嵌入维度）
        self.usv_proj = nn.Linear(usv_dim, embedding_dim)
        self.task_proj = nn.Linear(task_dim + edge_dim, embedding_dim)  # 任务特征+边特征
        
        # 新增：位置编码
        self.pos_encoding = PositionalEncoding(embedding_dim)
        
        # 前馈网络
        self.ffn = nn.Sequential(
            nn.Linear(embedding_dim, embedding_dim * 2),  # 升维
            nn.GELU(),  # 使用GELU激活函数
            nn.Dropout(dropout),
            nn.Linear(embedding_dim * 2, embedding_dim),  # 降维
            nn.Dropout(dropout)
        )
        self.ffn_norm = nn.LayerNorm(embedding_dim)  # 前馈网络的层归一化

    def forward(self, usv_features, task_features, usv_task_edges, usv_task_adj):
        # 类型转换
        usv_features = usv_features.to(dtype=self.dtype)
        task_features = task_features.to(dtype=self.dtype)
        usv_task_edges = usv_task_edges.to(dtype=self.dtype)
        
        B, U, _ = usv_features.shape  # B:批次, U:USV数量
        T = task_features.shape[1]  # T:任务数量
        
        # 核心修复：USV特征处理流程
        # 1. 先投影到embedding_dim
        usv_emb = self.usv_proj(usv_features)
        # 2. 添加位置编码
        usv_emb = self.pos_encoding(usv_emb, usv_features[:, :, :2])
        # 3. USV自注意力（现在维度匹配）
        usv_emb = self.usv_self_attn(usv_emb, usv_emb, usv_emb)
        
        # USV-Task交叉注意力
        # 组合任务特征和边特征（扩展维度以匹配USV数量）
        task_feat_combined = torch.cat([
            task_features.unsqueeze(1).expand(B, U, T, -1),  # 扩展到[B, U, T, task_dim]
            usv_task_edges  # [B, U, T, edge_dim]
        ], dim=-1)  # 拼接后维度：[B, U, T, task_dim+edge_dim]
        # 投影并重塑为[B, U*T, embedding_dim]
        task_proj = self.task_proj(task_feat_combined).view(B, U*T, -1)
        
        # 构建mask（基于邻接矩阵）
        mask = usv_task_adj.view(B, U, T)
        # 交叉注意力计算（输入重塑为[B, U*T, embedding_dim]）
        cross_attn_out = self.usv_task_attn(
            usv_emb.unsqueeze(2).expand(-1, -1, T, -1).contiguous().view(B, U*T, -1),
            task_proj,
            task_proj,
            mask.view(B, U*T, 1)  # mask维度：[B, U*T, 1]
        ).view(B, U, T, -1).mean(dim=2)  # 平均池化（合并任务维度）
        
        # 前馈网络
        ffn_out = self.ffn(cross_attn_out)
        usv_emb = self.ffn_norm(ffn_out + cross_attn_out)  # 残差+层归一化
        
        return usv_emb  # 返回USV嵌入

class EnhancedTaskNodeEmbedding(nn.Module):
    """增强版Task节点嵌入"""
    def __init__(self, task_dim: int, usv_embedding_dim: int, edge_dim: int, embedding_dim: int, 
                 eta: int = 3, num_heads: int = 4, dropout: float = 0.1):
        super().__init__()
        self.dtype = torch.float32
        self.eta = eta  # 初始邻居数量
        
        # 核心修复：多头注意力在embedding_dim上操作
        self.task_self_attn = MultiHeadGraphAttention(embedding_dim, embedding_dim, num_heads, dropout)  # 任务自注意力
        self.task_usv_attn = MultiHeadGraphAttention(embedding_dim, embedding_dim, num_heads, dropout)  # 任务-USV交叉注意力
        
        # 投影层
        self.task_proj = nn.Linear(task_dim, embedding_dim)  # 任务特征投影
        self.edge_proj = nn.Linear(edge_dim, embedding_dim)  # 边特征投影
        self.usv_proj = nn.Linear(usv_embedding_dim, embedding_dim)  # USV嵌入投影
        
        # 新增：位置编码
        self.pos_encoding = PositionalEncoding(embedding_dim)
        
        # 改进：更深的前馈网络
        self.ffn = nn.Sequential(
            nn.Linear(embedding_dim, embedding_dim * 4),  # 升维4倍
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(embedding_dim * 4, embedding_dim * 2),  # 降维到2倍
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(embedding_dim * 2, embedding_dim)  # 降维到嵌入维度
        )
        self.ffn_norm = nn.LayerNorm(embedding_dim)  # 前馈网络层归一化

    def forward(self, task_features, usv_embeddings, task_task_edges, task_positions):
        # 类型转换
        task_features = task_features.to(dtype=self.dtype)
        usv_embeddings = usv_embeddings.to(dtype=self.dtype)
        task_task_edges = task_task_edges.to(dtype=self.dtype)
        
        B, T, _ = task_features.shape  # B:批次, T:任务数量
        U = usv_embeddings.shape[1]  # U:USV数量
        
        # 核心修复：Task特征处理流程
        # 1. Task投影到embedding_dim
        task_emb = self.task_proj(task_features)
        # 2. 位置编码
        task_emb = self.pos_encoding(task_emb, task_positions)
        
        # 改进：基于学习的邻居选择而非固定eta
        with torch.no_grad():  # 不参与梯度计算
            # 计算任务间距离（位置距离）
            distances = torch.cdist(task_positions, task_positions)
            # 自适应邻居数量（至少3个，最多eta+2，或总任务数的1/4）
            adaptive_k = min(max(3, T // 4), self.eta + 2)
            # 选择距离最近的k个邻居
            _, neighbor_idx = torch.topk(distances, k=adaptive_k, dim=-1, largest=False)
            # 构建邻居掩码（1表示有效邻居）
            neighbor_mask = torch.zeros_like(distances)
            batch_idx = torch.arange(B).unsqueeze(-1).unsqueeze(-1)
            task_idx = torch.arange(T).unsqueeze(0).unsqueeze(-1)
            neighbor_mask[batch_idx, task_idx, neighbor_idx] = 1.0
        
        # 3. Task自注意力（现在维度匹配）
        task_emb = self.task_self_attn(task_emb, task_emb, task_emb, neighbor_mask)
        
        # Task-USV交叉注意力
        usv_proj = self.usv_proj(usv_embeddings)  # USV嵌入投影
        task_usv_out = self.task_usv_attn(task_emb, usv_proj, usv_proj)  # 任务关注USV
        
        # 前馈网络
        ffn_out = self.ffn(task_usv_out)
        task_emb = self.ffn_norm(ffn_out + task_usv_out)  # 残差+层归一化
        
        return task_emb  # 返回任务嵌入

class GraphLevelAttentionPooling(nn.Module):
    """新增：图级别注意力池化"""
    def __init__(self, embedding_dim: int, output_dim: int):
        super().__init__()
        # 注意力网络（计算每个节点的重要性权重）
        self.attention = nn.Sequential(
            nn.Linear(embedding_dim, embedding_dim // 2),
            nn.Tanh(),
            nn.Linear(embedding_dim // 2, 1)
        )
        # 输出投影（组合USV和任务的全局特征）
        self.output_proj = nn.Linear(embedding_dim * 2, output_dim)
        self.layer_norm = nn.LayerNorm(output_dim)  # 层归一化
    
    def forward(self, usv_embeddings, task_embeddings):
        # USV池化：计算注意力权重并加权求和
        usv_attn_weights = F.softmax(self.attention(usv_embeddings), dim=1)  # [B, U, 1]
        usv_global = torch.sum(usv_attn_weights * usv_embeddings, dim=1)  # [B, embedding_dim]
        
        # Task池化：同上
        task_attn_weights = F.softmax(self.attention(task_embeddings), dim=1)  # [B, T, 1]
        task_global = torch.sum(task_attn_weights * task_embeddings, dim=1)  # [B, embedding_dim]
        
        # 组合全局特征
        graph_emb = torch.cat([usv_global, task_global], dim=-1)  # [B, 2*embedding_dim]
        graph_emb = self.output_proj(graph_emb)  # 投影到输出维度
        return self.layer_norm(graph_emb)  # 层归一化
```


#### 4. ppo_policy.py
实现PPO强化学习算法，包含Actor-Critic网络、记忆存储和学习率调度
```python
from typing import Dict, Tuple
import torch
torch.set_default_dtype(torch.float32)
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import copy
import math

class Memory:
    # 存储训练数据的记忆缓冲区
    def __init__(self):
        # 初始化存储列表
        self.states, self.actions, self.logprobs, self.rewards, self.is_terminals, self.values = [],[],[],[],[],[]
        self.usv_features, self.task_features, self.action_masks = [],[],[]
        self.usv_task_edges = []

    def clear_memory(self):
        # 清空记忆
        for lst in [self.states, self.actions, self.logprobs, self.rewards, self.is_terminals, 
                    self.values, self.usv_features, self.task_features, self.action_masks, self.usv_task_edges]:
            lst.clear()

    def add(self, state, action, logprob, reward, is_terminal, value, usv_task_edges):
        # 向记忆添加数据（带类型检查和验证）
        def _convert_and_validate(data, name):
            # 转换为Tensor并检查有效性
            if isinstance(data, np.ndarray):
                tensor = torch.from_numpy(data)
            elif isinstance(data, torch.Tensor):
                tensor = data
            else:
                raise TypeError(f"{name} must be numpy array or torch tensor")
            
            # 检查NaN和Inf
            if torch.isnan(tensor).any():
                raise ValueError(f"NaN values detected in {name}")
            if torch.isinf(tensor).any():
                raise ValueError(f"Inf values detected in {name}")
            return tensor

        try:
            # 提取并验证状态中的特征
            usv_features = _convert_and_validate(state['usv_features'], 'usv_features')
            task_features = _convert_and_validate(state['task_features'], 'task_features')
            action_mask = _convert_and_validate(state['action_mask'], 'action_mask')
            
            # 添加到记忆
            self.states.append(state)
            self.actions.append(torch.tensor(action, dtype=torch.float32))
            self.logprobs.append(torch.tensor(logprob, dtype=torch.float32))
            self.rewards.append(float(reward))
            self.is_terminals.append(bool(is_terminal))
            self.values.append(float(value))
            self.usv_features.append(usv_features)
            self.task_features.append(task_features)
            self.action_masks.append(action_mask)
            self.usv_task_edges.append(usv_task_edges if isinstance(usv_task_edges, torch.Tensor) 
                                     else torch.from_numpy(usv_task_edges))
        except Exception as e:
            print(f"Error adding to memory: {str(e)}")
            print(f"State keys: {state.keys()}")
            if 'usv_features' in state:
                print(f"usv_features shape: {state['usv_features'].shape}")
            raise

class EnhancedActorNetwork(nn.Module):
    """增强版Actor网络（策略网络）"""
    def __init__(self, input_dim: int, hidden_dim: int, num_hidden_layers: int, output_dim: int, dropout: float = 0.1):
        super().__init__()
        
        # 改进：更深的网络架构
        layers = []
        dim = input_dim  # 当前维度
        
        # 输入投影层
        layers.extend([
            nn.Linear(dim, hidden_dim),
            nn.LayerNorm(hidden_dim),  # 层归一化
            nn.GELU(),  # 使用GELU替代Tanh
            nn.Dropout(dropout)
        ])
        dim = hidden_dim  # 更新维度
        
        # 主要隐藏层
        for i in range(num_hidden_layers):
            layers.extend([
                nn.Linear(dim, hidden_dim),
                nn.LayerNorm(hidden_dim),
                nn.GELU(),
                nn.Dropout(dropout)
            ])
            
            # 新增：残差连接（每两层）
            if i > 0 and i % 2 == 1:
                # 添加残差连接的标记，在forward中处理
                pass
        
        # 输出层
        layers.extend([
            nn.Linear(dim, hidden_dim // 2),
            nn.GELU(),
            nn.Dropout(dropout * 0.5),  # 输出层降低dropout
            nn.Linear(hidden_dim // 2, output_dim)
        ])
        
        # 构建模块列表
        self.layers = nn.ModuleList()
        for layer in layers:
            self.layers.append(layer)
        
        # 新增：注意力权重用于特征重要性
        self.feature_attention = nn.Sequential(
            nn.Linear(input_dim, input_dim // 4),
            nn.GELU(),
            nn.Linear(input_dim // 4, input_dim),
            nn.Sigmoid()  # 输出0-1权重
        )
        
        self._init_weights()  # 初始化权重
    
    def _init_weights(self):
        # 初始化线性层权重（正交初始化）
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.orthogonal_(m.weight, gain=math.sqrt(2))
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, usv_embeddings, task_embeddings, graph_embedding):
        B, U, E = usv_embeddings.shape  # B:批次, U:USV数, E:嵌入维度
        T = task_embeddings.shape[1]  # T:任务数
        
        # 改进：特征组合和注意力加权
        # 扩展维度以匹配（USV和任务的笛卡尔积）
        usv_exp = usv_embeddings.unsqueeze(2).expand(B, U, T, E)  # [B, U, T, E]
        task_exp = task_embeddings.unsqueeze(1).expand(B, U, T, E)  # [B, U, T, E]
        graph_exp = graph_embedding.unsqueeze(1).unsqueeze(1).expand(B, U, T, graph_embedding.shape[-1])  # [B, U, T, G]
        
        # 拼接特征：USV嵌入+任务嵌入+图全局嵌入
        feat = torch.cat([usv_exp, task_exp, graph_exp], dim=-1).view(B, U*T, -1)  # [B, U*T, E+E+G]
        
        # 新增：特征注意力加权（学习特征重要性）
        attn_weights = self.feature_attention(feat)  # [B, U*T, input_dim]
        feat = feat * attn_weights  # 加权
        
        # 改进：通过网络传播
        x = feat
        residual = None  # 残差缓存
        
        for i, layer in enumerate(self.layers):
            # 每8层添加一个残差连接
            if isinstance(layer, nn.Linear) and i > 8 and i % 8 == 0 and residual is not None:
                x = layer(x) + residual  # 残差连接
                residual = x
            else:
                x = layer(x)
                # 前8层的dropout后保存残差
                if isinstance(layer, nn.Dropout) and i < 8:
                    residual = x
        
        return x.squeeze(-1)  # 返回策略logits

class EnhancedCriticNetwork(nn.Module):
    """核心改进：更强的价值网络（Critic）"""
    def __init__(self, input_dim: int, hidden_dim: int, num_hidden_layers: int, dropout: float = 0.1):
        super().__init__()
        
        # 关键改进：增加网络深度和宽度
        enhanced_hidden_dim = hidden_dim * 2  # 增加宽度（2倍）
        enhanced_layers = max(num_hidden_layers + 2, 4)  # 增加深度（至少4层）
        
        layers = []
        dim = input_dim
        
        # 新增：多尺度特征提取
        self.multi_scale_proj = nn.ModuleList([
            nn.Linear(input_dim, enhanced_hidden_dim),  # 尺度1
            nn.Linear(input_dim, enhanced_hidden_dim // 2),  # 尺度2
            nn.Linear(input_dim, enhanced_hidden_dim // 4)  # 尺度3
        ])
        
        # 主网络
        layers.extend([
            # 组合多尺度特征
            nn.Linear(enhanced_hidden_dim + enhanced_hidden_dim//2 + enhanced_hidden_dim//4, enhanced_hidden_dim),
            nn.LayerNorm(enhanced_hidden_dim),
            nn.GELU(),
            nn.Dropout(dropout)
        ])
        
        # 改进：更深的隐藏层
        dim = enhanced_hidden_dim
        for i in range(enhanced_layers):
            layers.extend([
                nn.Linear(dim, enhanced_hidden_dim),
                nn.LayerNorm(enhanced_hidden_dim),
                nn.GELU(),
                nn.Dropout(dropout * (0.8 ** i))  # 逐层递减dropout（减少过拟合）
            ])
            
            # 新增：每隔两层添加残差连接
            if i > 0 and i % 2 == 1:
                layers.append(ResidualBlock(enhanced_hidden_dim, dropout))
        
        # 改进：多层输出头
        layers.extend([
            nn.Linear(enhanced_hidden_dim, enhanced_hidden_dim // 2),
            nn.GELU(),
            nn.Dropout(dropout * 0.5),
            nn.Linear(enhanced_hidden_dim // 2, enhanced_hidden_dim // 4),
            nn.GELU(),
            nn.Linear(enhanced_hidden_dim // 4, 1)  # 输出状态价值
        ])
        
        self.net = nn.Sequential(*layers)  # 主网络
        
        # 新增：价值范围预测辅助头（正则化价值输出）
        self.value_range_head = nn.Sequential(
            nn.Linear(input_dim, enhanced_hidden_dim // 2),
            nn.GELU(),
            nn.Linear(enhanced_hidden_dim // 2, 2)  # 预测价值的上下界
        )
        
        self._init_weights()  # 初始化权重
    
    def _init_weights(self):
        # 正交初始化
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.orthogonal_(m.weight, gain=math.sqrt(2))
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, graph_embedding):
        # 新增：多尺度特征提取
        multi_scale_feats = []
        for proj in self.multi_scale_proj:
            multi_scale_feats.append(F.gelu(proj(graph_embedding)))  # 每个尺度的特征
        
        # 组合多尺度特征
        combined_feat = torch.cat(multi_scale_feats, dim=-1)
        
        # 主价值预测
        value = self.net(combined_feat)
        
        # 新增：价值范围辅助监督
        value_range = self.value_range_head(graph_embedding)
        value_min, value_max = value_range[:, 0:1], value_range[:, 1:2]
        
        # 确保价值在合理范围内（截断）
        value = torch.clamp(value, value_min, value_max)
        
        return value  # 返回状态价值

class ResidualBlock(nn.Module):
    """新增：残差块（增强网络深度）"""
    def __init__(self, hidden_dim: int, dropout: float = 0.1):
        super().__init__()
        self.block = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim)
        )
        
    def forward(self, x):
        # 残差连接：输入+经过块处理的输入
        return F.gelu(x + self.block(x))

class AdaptiveLearningRateScheduler:
    """新增：自适应学习率调度器（基于性能调整）"""
    def __init__(self, optimizer, initial_lr: float = 1e-4, patience: int = 50, factor: float = 0.8):
        self.optimizer = optimizer  # 优化器
        self.initial_lr = initial_lr  # 初始学习率
        self.patience = patience  # 耐心值（多少步不提升则衰减）
        self.factor = factor  # 衰减因子
        # （后续可补充学习率调整逻辑）
```


#### 5. usv_env.py
定义USV任务调度环境，包含状态管理、动作执行和奖励计算
```python
from dataclasses import dataclass
from typing import Optional, List, Dict, Tuple
import numpy as np
from gymnasium import spaces

@dataclass
class USVState:
    # USV状态数据类
    id: int  # ID
    position: np.ndarray  # 位置坐标
    battery: float  # 电池电量
    status: str  # 状态（idle/busy等）
    current_task: Optional[int] = None  # 当前任务ID
    available_time: float = 0.0  # 可用时间（完成当前任务的时间）
    total_distance: float = 0.0  # 总航行距离
    work_time: float = 0.0  # 总工作时间
    assigned_tasks: Optional[List[int]] = None  # 已分配任务列表
    # 新增：记录上一个任务的位置，用于计算最小航行时间
    last_task_position: Optional[np.ndarray] = None

    def __post_init__(self):
        # 初始化可选字段
        if self.assigned_tasks is None:
            self.assigned_tasks = []
        if self.last_task_position is None:
            self.last_task_position = self.position.copy()  # 默认初始位置

@dataclass
class TaskState:
    # 任务状态数据类
    id: int  # ID
    position: np.ndarray  # 位置坐标
    processing_time: float  # 处理时间
    fuzzy_time: Tuple[float, float, float]  # 模糊时间（最小/最可能/最大）
    status: str  # 状态（unscheduled/scheduled/completed）
    assigned_usv: Optional[int] = None  # 分配的USV ID
    start_time: Optional[float] = None  # 开始时间
    completion_time: Optional[float] = None  # 完成时间

class USVEnv:
    def __init__(self, env_config: Dict):
        # 环境初始化
        self.num_usvs = int(env_config['num_usvs'])  # USV数量
        self.num_tasks = int(env_config['num_tasks'])  # 任务数量
        self.map_size = env_config['map_size']  # 地图尺寸
        self.usv_speed = float(env_config['usv_speed'])  # USV速度
        # 新增：最小航行时间约束配置
        self.min_travel_time = float(env_config.get('min_travel_time', 2.0))  # 默认最小航行时间2单位
        self.min_travel_distance = float(env_config.get('min_travel_distance', 5.0))  # 默认最小航行距离5单位
        self.travel_constraint_mode = env_config.get('travel_constraint_mode', 'time')  # 约束模式
        self.reward_config = env_config.get('reward_config', {})  # 奖励配置
        self.mask_config = env_config.get('dynamic_masking_config', {'enabled': False})  # 掩码配置
        print(f"[INFO] Reward Config: {self.reward_config}")
        print(f"[INFO] Masking Config: {self.mask_config}")
        print(f"[INFO] Travel Constraints - Min Time: {self.min_travel_time}, Min Distance: {self.min_travel_distance}, Mode: {self.travel_constraint_mode}")
        
        # 其他初始化
        self.action_space = spaces.Discrete(self.num_usvs * self.num_tasks)  # 动作空间（USV-任务对）
        self.usvs: List[USVState] = []  # USV列表
        self.tasks: List[TaskState] = []  # 任务列表
        self.makespan = 0.0  # 最大完成时间（调度长度）
        self.done = False  # 任务是否完成
        
        # 新增：用于奖励计算的历史信息
        self.previous_makespan = 0.0  # 上一步的makespan
        self.previous_unassigned_tasks = 0  # 上一步未分配的任务数
        self.step_count = 0  # 步数计数
        
        # 新增：调试信息
        self.debug_mode = True  # 调试模式

    def reset(self, tasks_data=None, usvs_data=None):
        """重置环境状态"""
        self.makespan = 0.0
        self.done = False
        self.schedule_history = []  # 调度历史
        self.step_count = 0
        self.previous_makespan = 0.0
        self.previous_unassigned_tasks = self.num_tasks  # 初始未分配任务数为总任务数
        
        # 初始化USV状态
        self.usvs = usvs_data or [
            USVState(
                id=i,
                position=np.zeros(2, dtype=np.float32),  # 初始位置(0,0)
                battery=float('inf'),  # 电池无限（简化）
                status='idle'  # 初始状态空闲
            )
            for i in range(self.num_usvs)
        ]
        
        # 初始化任务状态
        self.tasks = tasks_data or [
            TaskState(
                id=i,
                position=np.random.uniform(0, self.map_size, 2).astype(np.float32),  # 随机位置
                processing_time=np.random.uniform(8.0, 30.0),  # 随机处理时间
                fuzzy_time=(0, 0, 0),  # 模糊时间初始化为0
                status='unscheduled'  # 初始未调度
            )
            for i in range(self.num_tasks)
        ]
        
        # 重置时初始化last_task_position
        for usv in self.usvs:
            usv.last_task_position = usv.position.copy()
            
        # 修复：初始化时计算初始makespan（应该为0）
        self._update_current_makespan()
        
        if self.debug_mode:
            print(f"[DEBUG] Environment reset - Initial makespan: {self.makespan}")
            
        return self._get_observation()  # 返回初始观测

    def _get_observation(self):
        # 构建观测（USV特征和任务特征）
        usv_feats = np.array([
            [*u.position, u.available_time] for u in self.usvs  # 位置+可用时间
        ], dtype=np.float32)
        
        task_feats = np.array([
            [*t.position, t.processing_time, 1 if t.status == 'unscheduled' else 0] 
            # 位置+处理时间+是否未调度
            for t in self.tasks
        ], dtype=np.float32)
        
        return {
            'usv_features': usv_feats,
            'task_features': task_feats,
            'action_mask': self._compute_action_mask()  # 动作掩码（过滤无效动作）
        }

    def _compute_action_mask(self):
        # 计算动作掩码（1表示有效动作）
        mask = np.zeros(self.num_usvs * self.num_tasks, dtype=np.int8)
        tasks_per_usv = [len(u.assigned_tasks) for u in self.usvs]  # 每个USV的任务数
        avg_tasks = np.mean(tasks_per_usv) if tasks_per_usv else 0  # 平均任务数
        load_threshold = avg_tasks * self.mask_config.get('max_load_ratio', 1.5) + 1  # 负载阈值
        
        for ui in range(self.num_usvs):
            # 改进：更严格的负载均衡mask
            if self.mask_config.get('enabled', False):
                current_load = len(self.usvs[ui].assigned_tasks)
                min_load = min(len(u.assigned_tasks) for u in self.usvs)
                if current_load > min_load + 2:  # 不允许某个USV比最少的多超过2个任务
                    continue
                    
            # 只有在USV的可用时间点，它才能接受新任务
            is_available = self.usvs[ui].available_time <= (
                min(u.available_time for u in self.usvs if u.status != 'idle') 
                if any(u.status != 'idle' for u in self.usvs) else 0
            )
            
            if is_available:
                for ti in range(self.num_tasks):
                    if self.tasks[ti].status == 'unscheduled':  # 只考虑未调度任务
                        # 新增：检查是否满足最小航行时间约束
                        if self._check_travel_constraint(ui, ti):
                            mask[ui * self.num_tasks + ti] = 1  # 标记有效动作
                            
        return mask

    def _check_travel_constraint(self, usv_idx: int, task_idx: int) -> bool:
        """新增：检查USV到任务的航行是否满足最小时间/距离约束"""
        usv = self.usvs[usv_idx]
        task = self.tasks[task_idx]
        
        # 如果USV还没有执行过任务，不需要检查约束
        if len(usv.assigned_tasks) == 0:
            return True
            
        # 计算从上一个任务位置到新任务的距离和时间
        travel_distance = np.linalg.norm(usv.last_task_position - task.position)
        travel_time = travel_distance / self.usv_speed
        
        # 根据约束模式检查
        if self.travel_constraint_mode == 'time':
            return travel_time >= self.min_travel_time
        elif self.travel_constraint_mode == 'distance':
            return travel_distance >= self.min_travel_distance
        elif self.travel_constraint_mode == 'both':
            return travel_time >= self.min_travel_time and travel_distance >= self.min_travel_distance
        else:
            return True  # 如果模式未知，默认允许

    def step(self, action: int):
        """执行一个动作步骤"""
        # 检查动作是否有效（被掩码禁止）
        if self._compute_action_mask()[action] == 0:
            return self._get_observation(), -10.0, True, {'error': 'invalid_action', 'makespan': self.makespan}
            
        # 解析动作：USV索引和任务索引
        usv_idx = int(action // self.num_tasks)
        task_idx = int(action % self.num_tasks)
        
        # 修复：保存分配前的状态用于调试
        prev_makespan = self.makespan
        
        # 核心修复：先分配任务，再计算奖励
        self._assign_task_to_usv(usv_idx, task_idx)
        
        # 关键修复：立即更新当前makespan
        self._update_current_makespan()
        
        # 修复：使用更合理的奖励函数
        reward = self._compute_improved_reward(usv_idx, task_idx, prev_makespan)
        self.step_count += 1
        # 判断是否完成（所有任务都已调度）
        self.done = all(t.status != 'unscheduled' for t in self.tasks)
        
        # 修复：最终奖励调整
        if self.done:
            final_reward = self._compute_final_reward()
            reward += final_reward
            # 重要：最终验证makespan合理性
            if self.makespan <= 0 and any(t.processing_time > 0 for t in self.tasks):
                print(f"[ERROR] Invalid final makespan: {self.makespan}")
                reward -= 100.0  # 严重惩罚无效的makespan
                
        # 新增：makespan约束检查
        if self.makespan < 0:
            print(f"[ERROR] Negative makespan detected: {self.makespan}")
            reward -= 50.0
            self.makespan = max(u.available_time for u in self.usvs) if self.usvs else 0.0
            
        if self.debug_mode and self.step_count % 5 == 0:
            print(f"[DEBUG] Step {self.step_count}: makespan={self.makespan:.2f}, reward={reward:.2f}")
            
        info = {'makespan': float(self.makespan), 'step_count': self.step_count}
        return self._get_observation(), float(reward), bool(self.done), info

    def _update_current_makespan(self):
        """新增：实时更新当前makespan"""
        if not self.usvs:
            self.makespan = 0.0
            return
            
        # makespan = 所有USV中最大的完成时间
        all_completion_times = [u.available_time for u in self.usvs]
        self.makespan = max(all_completion_times) if all_completion_times else 0.0
        
        # 重要：确保makespan不会无故为0
        if self.makespan <= 0 and any(len(u.assigned_tasks) > 0 for u in self.usvs):
            # 如果有任务被分配但makespan为0，这是异常情况
            print(f"[WARNING] Makespan inconsistency detected. Recalculating...")
            self._recalculate_makespan()

    def _recalculate_makespan(self):
        """新增:重新计算makespan以修复异常"""
        # （实际实现中会遍历任务完成时间重新计算）
        pass

    # 以下为省略的辅助方法（_assign_task_to_usv, _compute_improved_reward等）
    def _assign_task_to_usv(self, usv_idx, task_idx):
        # 分配任务给USV的逻辑（更新USV和任务状态）
        pass
        
    def _compute_improved_reward(self, usv_idx, task_idx, prev_makespan):
        # 计算奖励的逻辑（结合makespan改进、负载均衡等）
        return 0.0
        
    def _compute_final_reward(self):
        # 计算最终奖励（任务完成时的额外奖励）
        return 0.0
```


#### 6. vis_manager.py
可视化工具，支持实时训练曲线和调度结果甘特图
```python
"""
Visualization manager for optional live plots (Visdom) and static Gantt charts.
- Visdom 连接稳健(连不上自动降级,env 固定为传入的 viz_name)
- 训练曲线首次自动建窗口，后续 append,并保存面板
- 甘特图：任务段彩色（按 USV 固定色），"航行时间"统一灰色 Transit time
- 去掉尾部补灰（避免把长时间的空闲误画成航行）
- 额外导出"USV 工作负载汇总表"
- 新增：甘特图对短任务的自适应文本渲染
- 新增：支持平衡指标的实时绘图
- 9.2修改_序号27: 修复中文字体显示问题
"""
import os
from typing import Dict, List, Any, Optional, Tuple
import json
import random
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches

# 9.2修改_序号28: 设置matplotlib中文字体支持
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Liberation Sans', 'Arial Unicode MS', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题

try:
    import visdom  # 尝试导入visdom（实时可视化）
except ImportError:
    visdom = None

class VisualizationManager:
    def __init__(self, viz_name: str, enabled: bool = True, **kwargs):
        self.enabled = bool(enabled) and visdom is not None  # 是否启用可视化
        self.env = viz_name  # 可视化环境名称
        self.viz = None  # visdom实例
        self.plots = {}  # 存储图表窗口
        self.colors = self._load_colors()  # 加载颜色配置
        if self.enabled:
            try:
                # 初始化visdom
                self.viz = visdom.Visdom(env=viz_name, use_incoming_socket=False,** kwargs)
                if self.viz.check_connection():
                    self._init_windows()  # 初始化窗口
                    print(f"============================================\n[INFO] Visdom Environment Name: {viz_name}\n打开浏览器访问: http://{kwargs.get('server', 'localhost')}:{kwargs.get('port', 8097)} 并切换到该 Environment\n============================================")
                else:
                    self.enabled = False
                    print("⚠️ Visdom connection failed. Live plotting disabled.")
            except Exception as e:
                self.enabled = False
                print(f"⚠️ Visdom init failed: {e}")

    def _init_windows(self):
        # 初始化可视化窗口
        if not self.viz: return
        import torch
        
        # 定义需要绘制的图表
        plot_configs = {
            'train_makespan': {'title': 'Makespan'},  # 最大完成时间
            'train_reward': {'title': 'Reward'},  # 奖励
            'actor_loss': {'title': 'Actor Loss'},  # Actor损失
            'critic_loss': {'title': 'Critic Loss'},  # Critic损失
            'jains_index': {'title': "Fairness (Jain's Index)"},  # 公平性指标
            'task_load_variance': {'title': 'Task Load Variance'},  # 负载方差
        }
        # 创建窗口
        for key, config in plot_configs.items():
            opts_with_legend = config.copy()
            opts_with_legend['legend'] = ['train', 'eval']  # 训练/评估曲线
            self.plots[key] = self.viz.line(
                X=np.array([0]), Y=np.array([np.nan]), name='train', opts=opts_with_legend
            )

    def update_plots(self, episode, metrics):
        # 更新图表数据
        if not self.enabled: return
        import torch
        for key, value in metrics.items():
            if key in self.plots:
                # 更新训练曲线
                self.viz.line(X=torch.tensor([episode]), Y=torch.tensor([value]), 
                              win=self.plots[key], update='append', name='train')
            
            # 检查是否有评估数据
            eval_key = f"eval_{key.replace('train_', '')}"
            if eval_key in metrics and key in self.plots:
                 # 更新评估曲线
                 self.viz.line(X=torch.tensor([episode]), Y=torch.tensor([metrics[eval_key]]), 
                              win=self.plots[key], update='append', name='eval')

    def _load_colors(self) -> List[str]:
        # 加载颜色配置（用于甘特图）
        path_options = ['./color_config.json', 'usv_agent/color_config.json', 'utils/color_config.json']
        for p in path_options:
            if os.path.exists(p):
                try:
                    with open(p, 'r', encoding='utf-8') as f:
                        return json.load(f).get('gantt_color', [])
                except Exception:
                    continue
        # 默认颜色列表
        return ["#FC5E55", "#B3E159", "#2C9CFF", "#F5D43E", "#AA5FBA", "#7780FE"]

    def _color_for_usv(self, u_id: int) -> str:
        # 获取USV对应的颜色（循环使用）
        if u_id < len(self.colors): return self.colors[u_id]
        random.seed(u_id)  # 确保同一ID颜色一致
        return "#" + "".join(random.choice("0123456789ABCDEF") for _ in range(6))  # 随机颜色

    def _extract_tasks(self, env) -> Tuple[Dict[int, List[Dict]], int, float, float]:
        """稳健的任务信息提取，基于调试版本的成功经验"""
        num_usvs = int(getattr(env, "num_usvs", 0))  # USV数量
        makespan = float(getattr(env, "makespan", 0.0))  # makespan
        text_thresh = float(getattr(env, "min_task_time_visual", 5.0))  # 文本显示阈值
        
        task_positions = {}  # 任务位置
        
        # 提取任务位置
        if hasattr(env, "tasks") and env.tasks:
            for i, task in enumerate(env.tasks):
                task_id = getattr(task, 'task_id', i)
                
                # 尝试多种属性名获取位置
                position = None
                for pos_attr in ['position', 'pos', 'location', 'coord']:
                    if hasattr(task, pos_attr):
                        position = getattr(task, pos_attr)
                        break
                
                if position is None and hasattr(task, 'x') and hasattr(task, 'y'):
                    position = (getattr(task, 'x'), getattr(task, 'y'))
                
                if position is not None and len(position) >= 2:
                    task_positions[task_id] = (float(position[0]), float(position[1]))
                else:
                    task_positions[task_id] = (0.0, 0.0)
        
        elif hasattr(env, 'task_features'):
            task_features = env.task_features
            if hasattr(task_features, 'shape') and len(task_features.shape) >= 2:
                if task_features.shape[1] >= 2:
                    for i in range(task_features.shape[0]):
                        task_positions[i] = (float(task_features[i, 0]), float(task_features[i, 1]))
        
        # 提取每个USV的任务列表
        per_usv: Dict[int, List[Dict]] = {u: [] for u in range(num_usvs)}
        if hasattr(env, "schedule_history"):
            for rec in env.schedule_history:
                task_id = rec["task"]
                task_pos = task_positions.get(task_id, (0, 0))
                
                per_usv.setdefault(rec['usv'], []).append({
                    "task": task_id, 
                    "start": float(rec["start_time"]), 
                    "end": float(rec["completion_time"]),
                    "position": task_pos
                })
        
        # 按开始时间排序
        for u in per_usv:
            per_usv[u].sort(key=lambda x: x["start"])
        
        return per_usv, num_usvs, makespan, text_thresh

    def generate_gantt_chart(self, env, save_path: Optional[str] = None, show: bool = False):
        """9.2修改_序号29: 修复标签显示逻辑，使用英文避免字体问题"""
        per_usv, num_usvs, makespan, text_thresh = self._extract_tasks(env)

        # 创建图表
        fig, ax = plt.subplots(figsize=(20, 2.5 + num_usvs * 0.8))
        bar_h, transit_color = 0.6, "#D0D0D0"  # 条形高度，航行时间颜色（灰色）
        summary = []  # 汇总信息

        for u in range(num_usvs):
            items, y = per_usv.get(u, []), u  # 任务列表，y轴位置（USV ID）
            prev_end, task_time, transit_time = 0.0, 0.0, 0.0  # 上一任务结束时间，任务时间，航行时间

            for it in items:
                s, e = it["start"], it["end"]  # 任务开始和结束时间
                task_pos = it.get("position", (0, 0))  # 任务位置
                
                # 绘制航行时间（上一任务结束到当前任务开始）
                if s > prev_end:
                     ax.barh(y, width=(s - prev_end), left=prev_end, height=bar_h, 
                             color=transit_color, edgecolor='grey', alpha=0.5)
                     transit_time += (s - prev_end)  # 累计航行时间
                
                task_duration = e - s  # 任务持续时间
                if task_duration > 1e-6:  # 有效任务
                    # 绘制任务矩形（彩色）
                    ax.barh(y, width=task_duration, left=s, height=bar_h,
                            color=self._color_for_usv(u), edgecolor='black', alpha=0.95)
                    
                    # 9.2修改_序号30: 确保所有任务都显示完整信息
                    task_id = it['task']
                    pos_x, pos_y = task_pos[0], task_pos[1]
                    
                    # 统一的标签格式，确保坐标和时间信息都显示
                    if task_duration > text_thresh * 1.5:  # 长任务：矩形内显示完整信息
                        label = f"T{task_id}\n({pos_x:.0f},{pos_y:.0f})\n{s:.0f}-{e:.0f}"
                        ax.text(s + task_duration / 2, y, label, ha='center', va='center',
                                color='white', fontsize=8, weight='bold', 
                                bbox=dict(boxstyle="round,pad=0.2", facecolor='black', alpha=0.4))
                                
                    elif task_duration > text_thresh * 0.8:  # 中等任务：矩形内显示ID和坐标，时间信息在上方
                        main_label = f"T{task_id}\n({pos_x:.0f},{pos_y:.0f})"
                        time_label = f"{s:.0f}-{e:.0f}"
                        
                        ax.text(s + task_duration / 2, y, main_label, ha='center', va='center',
                                color='white', fontsize=7, weight='bold')
                        ax.text(s + task_duration / 2, y + bar_h + 0.05, time_label, 
                                ha='center', va='bottom', color='darkblue', fontsize=6,
                                bbox=dict(boxstyle="round,pad=0.1", facecolor='lightcyan', alpha=0.8))
                                
                    else:  # 短任务：分层显示，确保所有信息都可见
                        # 主标签在矩形内
                        main_label = f"T{task_id}"
                        ax.text(s + task_duration / 2, y, main_label, ha='center', va='center',
                                color='white', fontsize=7, weight='bold')
                        
                        # 坐标和时间在矩形上方
                        pos_label = f"({pos_x:.0f},{pos_y:.0f})"
                        time_label = f"{s:.0f}-{e:.0f}"
                        ax.text(s + task_duration / 2, y + bar_h + 0.05, pos_label, 
                                ha='center', va='bottom', color='darkgreen', fontsize=6,
                                bbox=dict(boxstyle="round,pad=0.1", facecolor='lightgreen', alpha=0.8))
                        ax.text(s + task_duration / 2, y + bar_h + 0.25, time_label, 
                                ha='center', va='bottom', color='darkred', fontsize=6,
                                bbox=dict(boxstyle="round,pad=0.1", facecolor='lightpink', alpha=0.8))
                
                task_time += task_duration  # 累计任务时间
                prev_end = max(prev_end, e)  # 更新上一任务结束时间

            # 设置y轴标签（USV ID）
            ax.text(-makespan * 0.02, y, f"USV {u}", ha='right', va='center', fontweight='bold')
            summary.append({
                "usv_id": u,
                "total_tasks": len(items),
                "task_time": task_time,
                "transit_time": transit_time,
                "utilization": task_time / max(prev_end, 1e-6)  # 利用率
            })

        # 设置坐标轴和标题
        ax.set_xlabel("Time", fontsize=12)
        ax.set_ylabel("USV ID", fontsize=12)
        ax.set_title(f"Task Schedule (Makespan: {makespan:.1f})", fontsize=14, pad=20)
        ax.set_xlim(0, makespan * 1.05)  # x轴范围
        ax.set_ylim(-0.5, num_usvs - 0.5)  # y轴范围
        ax.grid(axis='x', linestyle='--', alpha=0.7)

        # 添加图例
        legend_items = [mpatches.Patch(color=transit_color, label='Transit Time')]
        for u in range(min(num_usvs, len(self.colors))):
            legend_items.append(mpatches.Patch(color=self._color_for_usv(u), label=f'USV {u} Tasks'))
        ax.legend(handles=legend_items, loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=5)

        plt.tight_layout()

        # 保存或显示图表
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        if show:
            plt.show()
        plt.close(fig)

        # 输出USV工作负载汇总
        print("\nUSV Workload Summary:")
        for item in summary:
            print(f"USV {item['usv_id']}: Tasks={item['total_tasks']}, Task Time={item['task_time']:.1f}, "
                  f"Transit Time={item['transit_time']:.1f}, Utilization={item['utilization']:.2%}")
```